# Implementation of a basic regression decision tree.
# Input data set must be 1-dimensional with continuous labels.
# Output: The decision tree maps a real number input to a real number output.

#import numpy as np

class DecisionTree
    fn init(self.depth = 5, self.min-leaf-size = 5)
        decision-boundary = 0
        left = None
        right = None
        prediction = None

    fn mean-squared-error(label, prediction)
        # @param labels: a one dimensional numpy array
        # @param prediction: a floating point value
        # returns: error if prediction is used to estimate the labels
        if labels.ndim != 1
            print("Error: Input labels must be one dimensional")

        return np.mean((labels - prediction) ** 2)

    fn train(x: np.array, y: np.array)
        # @param x: a one dimensional numpy array
        # @param y: a one dimensional numpy array.
        # The contents of y are the labels for the corresponding x values.
        
        # this section is to check that the inputs conform to our dimensionality constraints
        if x.ndim != 1
            print("Error: Input data set must be one dimensional")
            return
        if x.len != y.len
            print("Error: x and y have different lengths")
            return
        if y.ndim != 1
            print("Error: Data set labels must be one dimensional")
            return

        if x.len < 2 * min-leaf-size or depth == 1
            prediction = np.mean(y)
            return

        best-split = 0
        min-error = mean-squared-error(x,np.mean(y)) * 2

        # loop over all possible splits for the decision tree. find the best split.
        # if no split exists that is less than 2 * error for the entire array
        # then the data set is not split and the average for the entire array is used as the predictor
        for i in 0...x.len
            if x[:i].len < min-leaf-size or x[i:].len < min-leaf-size
                continue
            error-left = mean-squared-error(x[:i], np.mean(y[:i]))
            error-right = mean-squared-error(x[i:], np.mean(y[i:]))
            error = error-left + error-right
            if error < min-error
                best-split = i
                min-error = error

        if best-split != 0
            left-x = x[:best-split]
            left-y = y[:best-split]
            right-x = x[best-split:]
            right-y = y[best-split:]

            decision-boundary = x[best-split]
            left = DecisionTree(depth = depth - 1, min-leaf-size = min-leaf-size)
            right = DecisionTree(depth = depth - 1, min-leaf-size = min-leaf-size)
            left.train(left-x, left-y)
            right.train(right-x, right-y)
        else
            prediction = np.mean(y)

    fn predict(x: float)
        # @param x: a floating point value to predict the label of
        # the prediction function works by recursively calling the predict function
        # of the appropriate subtrees based on the tree's decision boundary
        if prediction is not None
            return prediction
        elif left or right is not None
            if x >= decision-boundary
                return right.predict(x)
            else
                return left.predict(x)
        else
            print("Error: Decision tree not yet trained")
            return None

fn main
    # In this demonstration we're generating a sample data set from the sin function in numpy.
    # We then train a decision tree on the data set and use the decision tree to predict the
    # label of 10 different test values. Then the mean squared error over this test is displayed.
    x = np.arange(-1.0, 1.0, 0.005)
    y = np.sin(x)

    tree = DecisionTree(depth = 10, min-leaf-size = 10)
    tree.train(x,y)

    test-cases = (np.random.rand(10) * 2) - 1
    predictions = np.array([tree.predict(x) for x in test-cases])
    avg-error = np.mean((predictions - test-cases) ** 2)

    print("Test values: " + test-cases)
    print("Predictions: " + predictions)
    print("Average error: " + avg-error)